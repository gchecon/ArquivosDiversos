{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExtrairPubPDF",
      "provenance": [],
      "authorship_tag": "ABX9TyOa6vECmV1TXJbYv2wvaWpy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gchecon/ArquivosDiversos/blob/main/ExtrairPubPDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk-7F6edp6qA"
      },
      "source": [
        "# Importação de PDF diretamente do site \"https://www.tce.sp.gov.br/publicacoes\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wACnTzn5pVHn"
      },
      "source": [
        "import requests # Utilização desta biblioteca simples\n",
        "import sys      # Para finalização em caso de erro no programa compilado\n",
        "import re       # Manipulação de String\n",
        "import os.path  # Verificação se um arquivo existe para não baixar"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRbaw8o4qcHQ"
      },
      "source": [
        "url = \"https://www.tce.sp.gov.br/publicacoes?tipo=All&busca=&page=\"\n",
        "url_base = \"https://www.tce.sp.gov.br/publicacoes\"\n",
        "pag = 0\n",
        "url_work = url+str(pag)\n",
        "r = requests.get(url_work)\n",
        "lista = []\n",
        "idx = 16\n",
        "while idx > 1:  \n",
        "    # selecionar todas referências iniciadas por \"https://www.tce.sp.gov.br/publicacoes\"\n",
        "    # neste momento, para fins de teste, pegar apenas a primeira página\n",
        "    pag += 1\n",
        "    idx = len(re.findall(url_base, r.text))\n",
        "    str1 = r.text\n",
        "    i = 0\n",
        "    while i < idx:\n",
        "        i += 1\n",
        "        m = re.search(url_base, str1)\n",
        "        str1 = str1[m.start():len(str1)]\n",
        "        str2 = str1[37]\n",
        "        if str2 == '/':\n",
        "            str2 = str1[0:37]\n",
        "            str1 = str1[37:len(str1)]\n",
        "            str2 = str2 + str1[0:re.search('\"',str1).start()]\n",
        "            lista.append(str2)\n",
        "        else:\n",
        "            str1 = str1[37:len(str1)]   \n",
        "    url_work = url+str(pag)\n",
        "    r = requests.get(url_work)\n",
        "    # print(lista)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0h3ZzUjrGUD"
      },
      "source": [
        "# Baixar e Salvar PDFs em memória"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leuYbW_oq8W6",
        "outputId": "283af4fa-5a42-45ce-b123-3e9a11af0198"
      },
      "source": [
        "# lista[] contém todas as urls que apontam para os artigos. \n",
        "# O programa agora deve criar outra lista com os apontamentos para os arquivos PDF\n",
        "# Na url, existem várias citações do mesmo arquivo. Desta forma, somente a primeira ocorrência é utilizada\n",
        "lista_pdf = []\n",
        "total_de_arquivos = 0\n",
        "for str1 in lista:\n",
        "    r = requests.get(str1)\n",
        "    if r.status_code == 200:\n",
        "        # Baixar e salvar PDFs\n",
        "        str2 = r.text\n",
        "        pos = re.search('.pdf', str2).start()\n",
        "        lpos = 4\n",
        "        while pos > 0:\n",
        "            pos = pos - 1\n",
        "            lpos += 1\n",
        "            if str2[pos:pos+5] == 'https': \n",
        "                lista_pdf.append(str2[pos:pos+lpos])\n",
        "                total_de_arquivos += 1\n",
        "                break\n",
        "            else: \n",
        "                continue\n",
        "    else:\n",
        "        print(\"Não foi possível acessar o link \",str1)\n",
        "print(\"Total de arquivos: %i\" % total_de_arquivos)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de arquivos: 131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgY3xvsStb4U"
      },
      "source": [
        "# Salvar todos os links que apontam para os PDFs, juntamente com os arquivos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJEIMj7ZtlU2"
      },
      "source": [
        "# Preparação do aquivo que conterá todos as urls que apontam para os arquivos para\n",
        "# posterior montagem de um iframe http\n",
        "str_end = './PubResumo/Referencia/Enderecos.txt'\n",
        "try: \n",
        "    end_list = open(str_end, 'w')\n",
        "except:\n",
        "    print(\"Problemas na abertura do arquivo \"+str_end)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufrKyGH2t1p9"
      },
      "source": [
        "# Salvar todos os arquivos da list_pdf em diretório específico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_YsrLmOt6x3"
      },
      "source": [
        "# Salvar todos os arquivos da list_pdf em diretório específico\n",
        "grav = 0\n",
        "existentes = 0\n",
        "falha = 0\n",
        "log = []\n",
        "for str1 in lista_pdf:\n",
        "    # Extrair nome do arquivo\n",
        "    pos = len(str1)\n",
        "    while pos > 0:\n",
        "        pos = pos - 1\n",
        "        if str1[pos] == '/':\n",
        "            break\n",
        "    str2 = str1[pos+1:len(str1)]\n",
        "    str2 = './PubResumo/PDF/'+str2\n",
        "    if os.path.exists(str2) == True:\n",
        "        log.append(\"Existente: \"+str2)\n",
        "        end_list.write(str1+'\\n')\n",
        "        existentes += 1\n",
        "    else:\n",
        "        r = requests.get(str1)\n",
        "        if r.status_code == requests.codes.OK:\n",
        "            with open(str2, 'wb') as arquivo:\n",
        "                arquivo.write(r.content)\n",
        "                log.append(\"Gravado:   \"+str2)\n",
        "                end_list.write(str1+'\\n')\n",
        "                grav += 1\n",
        "                arquivo.close()\n",
        "        else:\n",
        "            falha += 1\n",
        "            log.append(\"Erro:      \"+str2)\n",
        "log.append(\"Total de Gravados:.. \"+str(grav))\n",
        "log.append(\"Total de Existentes: \"+str(existentes))\n",
        "log.append(\"Total de Falhas:.... \"+str(falha))\n",
        "with open(\"Relatorio.txt\",\"w\") as rel_log:\n",
        "    for str3 in log:\n",
        "        rel_log.write(str3+'\\n')\n",
        "end_list.close()\n",
        "rel_log.close()"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}